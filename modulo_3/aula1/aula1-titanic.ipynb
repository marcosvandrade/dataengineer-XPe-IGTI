{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark entry point\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Aula Interativa 1 - Engenharia de Dados - Apache Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a planilha CSV\n",
    "titanic_df_1 = spark.read.csv('titanic-partial-1.csv',header='True',inferSchema='False')\n",
    "\n",
    "# Detalhes dos atributos em https://www.kaggle.com/c/titanic/data?select=train.csv\n",
    "titanic_df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(Fare)='93.5')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df_1.agg({\"Fare\": \"max\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a planilha CSV\n",
    "titanic_df_2 = spark.read.csv('titanic-partial-2.csv',header='True',inferSchema='True')\n",
    "\n",
    "# Detalhes dos atributos em https://www.kaggle.com/c/titanic/data?select=train.csv\n",
    "titanic_df_2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df_2 = titanic_df_2.withColumnRenamed(\"Gender\", \"Sex\")\n",
    "\n",
    "titanic_df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = titanic_df_1.union(titanic_df_2)\n",
    "\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df_3 = titanic_df.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df_3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: long (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      "\n",
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|          1|       0|\n",
      "|          2|       1|\n",
      "|          3|       1|\n",
      "|          4|       1|\n",
      "|          5|       0|\n",
      "|          6|       0|\n",
      "|          7|       0|\n",
      "|          8|       0|\n",
      "|          9|       1|\n",
      "|         10|       1|\n",
      "|         11|       1|\n",
      "|         12|       1|\n",
      "|         13|       0|\n",
      "|         14|       0|\n",
      "|         15|       0|\n",
      "|         16|       1|\n",
      "|         17|       0|\n",
      "|         18|       1|\n",
      "|         19|       0|\n",
      "|         20|       1|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando o arquivo JSON\n",
    "\n",
    "survived_df = spark.read.json(\"titanic-survived.json\")\n",
    "survived_df.printSchema()\n",
    "survived_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Juntando os dois dataframes.\n",
    "\n",
    "titanic_df = titanic_df_3.join(survived_df, [\"PassengerId\"])\n",
    "\n",
    "titanic_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+---------------+-----+-----+--------+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|         Ticket| Fare|Cabin|Embarked|Survived|\n",
      "+-----------+------+--------------------+------+----+-----+-----+---------------+-----+-----+--------+--------+\n",
      "|        357|     1|Bowerman, Miss. E...|female|  22|    0|    1|         113505|   55|  E33|       S|       1|\n",
      "|        158|     3|     Corn, Mr. Harry|  male|  30|    0|    0|SOTON/OQ 392090| 8.05| null|       S|       0|\n",
      "|        171|     1|Van der hoef, Mr....|  male|  61|    0|    0|         111240| 33.5|  B19|       S|       0|\n",
      "|        197|     3| Mernagh, Mr. Robert|  male|null|    0|    0|         368703| 7.75| null|       Q|       0|\n",
      "|        320|     1|Spedden, Mrs. Fre...|female|  40|    1|    1|          16966|134.5|  E34|       C|       1|\n",
      "+-----------+------+--------------------+------+----+-----+-----+---------------+-----+-----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+--------+\n",
      "|Survived|                Name|Pclass|Embarked|\n",
      "+--------+--------------------+------+--------+\n",
      "|       1|Bowerman, Miss. E...|     1|       S|\n",
      "|       0|     Corn, Mr. Harry|     3|       S|\n",
      "|       0|Van der hoef, Mr....|     1|       S|\n",
      "|       0| Mernagh, Mr. Robert|     3|       Q|\n",
      "|       1|Spedden, Mrs. Fre...|     1|       C|\n",
      "|       1|Mellinger, Miss. ...|     2|       S|\n",
      "|       0|  Lahoud, Mr. Sarkis|     3|       C|\n",
      "|       0|Reuchlin, Jonkhee...|     1|       S|\n",
      "|       0|\"Sage, Miss. Doro...|     3|       S|\n",
      "|       1|McDermott, Miss. ...|     3|       Q|\n",
      "|       0|   Kantor, Mr. Sinai|     2|       S|\n",
      "|       0|Pengelly, Mr. Fre...|     2|       S|\n",
      "|       1|\"O'Leary, Miss. H...|     3|       Q|\n",
      "|       1|\"Ryerson, Miss. S...|     1|       C|\n",
      "|       0|Allum, Mr. Owen G...|     3|       S|\n",
      "|       0|  Gale, Mr. Shadrach|     2|       S|\n",
      "|       1|Silvey, Mrs. Will...|     1|       S|\n",
      "|       0|Downton, Mr. Will...|     2|       S|\n",
      "|       1|Lindqvist, Mr. Ei...|     3|       S|\n",
      "|       1|Hamalainen, Maste...|     2|       S|\n",
      "+--------+--------------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Survived\", \"Name\", \"Pclass\",\"Embarked\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+-----------------+-----------------+-----+--------+-------------------+\n",
      "|summary|       PassengerId|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|           Ticket|             Fare|Cabin|Embarked|           Survived|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+-----------------+-----------------+-----+--------+-------------------+\n",
      "|  count|               968|               968|                 968|   968|               790|               968|               968|              968|              968|  222|     965|                968|\n",
      "|   mean|414.48553719008265|2.3088842975206614|                null|  null|  29.4746835443038|0.5506198347107438|0.3956611570247934|269679.2738764045|32.26562438016525| null|    null|0.38636363636363635|\n",
      "| stddev| 269.3190497647826| 0.835264384848908|                null|  null|14.625063000563486|1.1211604031242766|0.8308066480923716|491794.1755212938|49.20622569057534| null|    null|0.48716727568510676|\n",
      "|    min|                 1|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                 0|           110152|                0|  A10|       C|                  0|\n",
      "|    max|                99|                 3|van Melkebeke, Mr...|  male|                 9|                 8|                 6|        WE/P 5735|             93.5|    T|       S|                  1|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+-----------------+-----------------+-----+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|               Age|             Fare|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               790|              968|\n",
      "|   mean|  29.4746835443038|32.26562438016525|\n",
      "| stddev|14.625063000563486|49.20622569057534|\n",
      "|    min|              0.42|                0|\n",
      "|    max|                 9|             93.5|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.describe('Age', 'Fare').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|               Age|             Fare|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               790|              968|\n",
      "|   mean|  29.4746835443038|32.26562438016525|\n",
      "| stddev|14.625063000563486|49.20622569057534|\n",
      "|    min|              0.42|                0|\n",
      "|    25%|              20.0|            7.925|\n",
      "|    50%|              28.0|             14.5|\n",
      "|    75%|              38.0|           31.275|\n",
      "|    max|                 9|             93.5|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select('Age', 'Fare').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       0|  594|\n",
      "|       1|  374|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Survived\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  505|\n",
      "|female|       1|  258|\n",
      "|female|       0|   89|\n",
      "|  male|       1|  116|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Sex\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|Pclass|Survived|count|\n",
      "+------+--------+-----+\n",
      "|     2|       1|   99|\n",
      "|     1|       0|   90|\n",
      "|     3|       1|  131|\n",
      "|     1|       1|  144|\n",
      "|     2|       0|  102|\n",
      "|     3|       0|  402|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Pclass\",\"Survived\").count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "| Initial|                Name|\n",
      "+--------+--------------------+\n",
      "|    Miss|Bowerman, Miss. E...|\n",
      "|      Mr|     Corn, Mr. Harry|\n",
      "|      Mr|Van der hoef, Mr....|\n",
      "|      Mr| Mernagh, Mr. Robert|\n",
      "|     Mrs|Spedden, Mrs. Fre...|\n",
      "|    Miss|Mellinger, Miss. ...|\n",
      "|      Mr|  Lahoud, Mr. Sarkis|\n",
      "|Jonkheer|Reuchlin, Jonkhee...|\n",
      "|    Miss|\"Sage, Miss. Doro...|\n",
      "|    Miss|McDermott, Miss. ...|\n",
      "|      Mr|   Kantor, Mr. Sinai|\n",
      "|      Mr|Pengelly, Mr. Fre...|\n",
      "|    Miss|\"O'Leary, Miss. H...|\n",
      "|    Miss|\"Ryerson, Miss. S...|\n",
      "|      Mr|Allum, Mr. Owen G...|\n",
      "|      Mr|  Gale, Mr. Shadrach|\n",
      "|     Mrs|Silvey, Mrs. Will...|\n",
      "|      Mr|Downton, Mr. Will...|\n",
      "|      Mr|Lindqvist, Mr. Ei...|\n",
      "|  Master|Hamalainen, Maste...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Initial\", regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "\n",
    "titanic_df.select(\"Initial\",\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Initial|\n",
      "+--------+\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|     Mme|\n",
      "|    Capt|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Miss|\n",
      "|  Other|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"Age\" is not a numeric column. Aggregation function can only be applied on a numeric column.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PEDRO~1.GUE\\AppData\\Local\\Temp/ipykernel_82988/493708000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\group.py\u001b[0m in \u001b[0;36m_api\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: \"Age\" is not a numeric column. Aggregation function can only be applied on a numeric column."
     ]
    }
   ],
   "source": [
    "titanic_df.groupby('Initial').avg('Age').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "titanic_df.filter(col(\"Initial\") == 'Miss').select(\"Name\", \"Age\", \"Initial\").show(5)\n",
    "\n",
    "titanic_df.filter(titanic_df.Initial == 'Miss').select(\"Name\", \"Age\", \"Initial\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.describe(\"Cabin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"Cabin\")\n",
    "\n",
    "titanic_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "titanic_df.groupBy(\"Family_Size\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "titanic_df.select(\"Name\", \"Family_Size\").orderBy(col(\"Family_Size\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n",
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", False)\n",
    "\n",
    "titanic_df.filter(titanic_df.Age > 70).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "\n",
    "titanic_df.orderBy(desc(\"age\")).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "titanic_df.orderBy(asc(\"age\")).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.stat.corr(\"age\", \"fare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.stat.corr(\"age\", \"family_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/api/python//reference/pyspark.sql/api/pyspark.sql.DataFrameStatFunctions.html#pyspark.sql.DataFrameStatFunctions\n",
    "titanic_df.stat.crosstab(\"Embarked\", \"PClass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy('pclass').agg({'fare': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|<lambda>(PassengerId)|\n",
      "+---------------------+\n",
      "|               233098|\n",
      "|               958292|\n",
      "|               882499|\n",
      "|               375525|\n",
      "|               892704|\n",
      "|               286538|\n",
      "|               372481|\n",
      "|               692364|\n",
      "|               217570|\n",
      "|               957970|\n",
      "|               385165|\n",
      "|               384321|\n",
      "|               265112|\n",
      "|                59420|\n",
      "|               508502|\n",
      "|               508568|\n",
      "|               442441|\n",
      "|               491999|\n",
      "|               855610|\n",
      "|               139434|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UDFs ajudam plugar funções complexas\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "import random\n",
    "\n",
    "# LGPD!\n",
    "def anonymize(passengerId):\n",
    "    return random.randint(1, 1000000)\n",
    "\n",
    "anonymizeUDF = udf(lambda passengerId:anonymize(passengerId), IntegerType())   \n",
    "\n",
    "titanic_df.select(anonymizeUDF(\"PassengerId\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os dados\n",
    "\n",
    "titanic_df.write.format(\"csv\").save(\"titanic-final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.select(\"name\", \"age\", \"survived\").write.format(\"parquet\").save(\"titanic-final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
